{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review_Classifier_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gpdsec/Beer_Review_Prediction/blob/master/Review_Classifier_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWZyYmS_UE_L",
        "colab_type": "text"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxkJoQBkUIHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaTwK7ojXr2F",
        "colab_type": "code",
        "outputId": "9b9cf69f-f78c-4e05-bddb-3f372f814bcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1E0Q3aoKUCRX",
        "colab_type": "text"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKWAkFVGUU0Z",
        "colab_type": "text"
      },
      "source": [
        "### Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXUkhkMfU4wq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "16166aed-6ffd-4e42-f702-1c733b28aae6"
      },
      "source": [
        "X = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Input/X_beer1.csv').astype(np.float32)\n",
        "X.columns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['beer/ABV', 'review/appearance', 'review/aroma', 'review/palate',\n",
              "       'review/taste', 'beer/style_Altbier',\n",
              "       'beer/style_American Adjunct Lager',\n",
              "       'beer/style_American Amber / Red Ale',\n",
              "       'beer/style_American Amber / Red Lager',\n",
              "       'beer/style_American Barleywine', 'beer/style_American Black Ale',\n",
              "       'beer/style_American Blonde Ale', 'beer/style_American Brown Ale',\n",
              "       'beer/style_American Dark Wheat Ale',\n",
              "       'beer/style_American Double / Imperial IPA',\n",
              "       'beer/style_American Double / Imperial Pilsner',\n",
              "       'beer/style_American Double / Imperial Stout',\n",
              "       'beer/style_American IPA', 'beer/style_American Malt Liquor',\n",
              "       'beer/style_American Pale Ale (APA)', 'beer/style_American Pale Lager',\n",
              "       'beer/style_American Pale Wheat Ale', 'beer/style_American Porter',\n",
              "       'beer/style_American Stout', 'beer/style_American Strong Ale',\n",
              "       'beer/style_American Wild Ale', 'beer/style_Baltic Porter',\n",
              "       'beer/style_Belgian Dark Ale', 'beer/style_Belgian IPA',\n",
              "       'beer/style_Belgian Pale Ale', 'beer/style_Belgian Strong Dark Ale',\n",
              "       'beer/style_Belgian Strong Pale Ale', 'beer/style_Berliner Weissbier',\n",
              "       'beer/style_BiÃ¨re de Garde', 'beer/style_Black & Tan',\n",
              "       'beer/style_Bock', 'beer/style_Braggot',\n",
              "       'beer/style_California Common / Steam Beer', 'beer/style_Chile Beer',\n",
              "       'beer/style_Cream Ale', 'beer/style_Czech Pilsener',\n",
              "       'beer/style_Doppelbock', 'beer/style_Dortmunder / Export Lager',\n",
              "       'beer/style_Dubbel', 'beer/style_Dunkelweizen', 'beer/style_Eisbock',\n",
              "       'beer/style_English Barleywine', 'beer/style_English Bitter',\n",
              "       'beer/style_English Brown Ale', 'beer/style_English Dark Mild Ale',\n",
              "       'beer/style_English India Pale Ale (IPA)',\n",
              "       'beer/style_English Pale Ale', 'beer/style_English Pale Mild Ale',\n",
              "       'beer/style_English Porter', 'beer/style_English Stout',\n",
              "       'beer/style_English Strong Ale', 'beer/style_Euro Dark Lager',\n",
              "       'beer/style_Euro Pale Lager', 'beer/style_Euro Strong Lager',\n",
              "       'beer/style_Extra Special / Strong Bitter (ESB)',\n",
              "       'beer/style_Flanders Oud Bruin', 'beer/style_Flanders Red Ale',\n",
              "       'beer/style_Foreign / Export Stout',\n",
              "       'beer/style_Fruit / Vegetable Beer', 'beer/style_German Pilsener',\n",
              "       'beer/style_Hefeweizen', 'beer/style_Herbed / Spiced Beer',\n",
              "       'beer/style_Irish Dry Stout', 'beer/style_Irish Red Ale',\n",
              "       'beer/style_Keller Bier / Zwickel Bier', 'beer/style_Kristalweizen',\n",
              "       'beer/style_KÃ¶lsch', 'beer/style_Lambic - Fruit',\n",
              "       'beer/style_Lambic - Unblended', 'beer/style_Light Lager',\n",
              "       'beer/style_Low Alcohol Beer', 'beer/style_Maibock / Helles Bock',\n",
              "       'beer/style_Milk / Sweet Stout', 'beer/style_Munich Dunkel Lager',\n",
              "       'beer/style_Munich Helles Lager', 'beer/style_MÃ¤rzen / Oktoberfest',\n",
              "       'beer/style_Oatmeal Stout', 'beer/style_Old Ale',\n",
              "       'beer/style_Pumpkin Ale', 'beer/style_Quadrupel (Quad)',\n",
              "       'beer/style_Rauchbier', 'beer/style_Russian Imperial Stout',\n",
              "       'beer/style_Rye Beer', 'beer/style_Saison / Farmhouse Ale',\n",
              "       'beer/style_Schwarzbier', 'beer/style_Scotch Ale / Wee Heavy',\n",
              "       'beer/style_Scottish Ale',\n",
              "       'beer/style_Scottish Gruit / Ancient Herbed Ale',\n",
              "       'beer/style_Smoked Beer', 'beer/style_Tripel',\n",
              "       'beer/style_Vienna Lager', 'beer/style_Weizenbock',\n",
              "       'beer/style_Wheatwine', 'beer/style_Winter Warmer',\n",
              "       'beer/style_Witbier'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pt03wbO2TnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Input/y_beer1.csv').astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7ukORUmMnwH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "9061a396-3089-434a-d18e-4466f804fe3c"
      },
      "source": [
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>beer/ABV</th>\n",
              "      <th>review/appearance</th>\n",
              "      <th>review/aroma</th>\n",
              "      <th>review/palate</th>\n",
              "      <th>review/taste</th>\n",
              "      <th>beer/style_Altbier</th>\n",
              "      <th>beer/style_American Adjunct Lager</th>\n",
              "      <th>beer/style_American Amber / Red Ale</th>\n",
              "      <th>beer/style_American Amber / Red Lager</th>\n",
              "      <th>beer/style_American Barleywine</th>\n",
              "      <th>beer/style_American Black Ale</th>\n",
              "      <th>beer/style_American Blonde Ale</th>\n",
              "      <th>beer/style_American Brown Ale</th>\n",
              "      <th>beer/style_American Dark Wheat Ale</th>\n",
              "      <th>beer/style_American Double / Imperial IPA</th>\n",
              "      <th>beer/style_American Double / Imperial Pilsner</th>\n",
              "      <th>beer/style_American Double / Imperial Stout</th>\n",
              "      <th>beer/style_American IPA</th>\n",
              "      <th>beer/style_American Malt Liquor</th>\n",
              "      <th>beer/style_American Pale Ale (APA)</th>\n",
              "      <th>beer/style_American Pale Lager</th>\n",
              "      <th>beer/style_American Pale Wheat Ale</th>\n",
              "      <th>beer/style_American Porter</th>\n",
              "      <th>beer/style_American Stout</th>\n",
              "      <th>beer/style_American Strong Ale</th>\n",
              "      <th>beer/style_American Wild Ale</th>\n",
              "      <th>beer/style_Baltic Porter</th>\n",
              "      <th>beer/style_Belgian Dark Ale</th>\n",
              "      <th>beer/style_Belgian IPA</th>\n",
              "      <th>beer/style_Belgian Pale Ale</th>\n",
              "      <th>beer/style_Belgian Strong Dark Ale</th>\n",
              "      <th>beer/style_Belgian Strong Pale Ale</th>\n",
              "      <th>beer/style_Berliner Weissbier</th>\n",
              "      <th>beer/style_BiÃ¨re de Garde</th>\n",
              "      <th>beer/style_Black &amp; Tan</th>\n",
              "      <th>beer/style_Bock</th>\n",
              "      <th>beer/style_Braggot</th>\n",
              "      <th>beer/style_California Common / Steam Beer</th>\n",
              "      <th>beer/style_Chile Beer</th>\n",
              "      <th>beer/style_Cream Ale</th>\n",
              "      <th>...</th>\n",
              "      <th>beer/style_Flanders Oud Bruin</th>\n",
              "      <th>beer/style_Flanders Red Ale</th>\n",
              "      <th>beer/style_Foreign / Export Stout</th>\n",
              "      <th>beer/style_Fruit / Vegetable Beer</th>\n",
              "      <th>beer/style_German Pilsener</th>\n",
              "      <th>beer/style_Hefeweizen</th>\n",
              "      <th>beer/style_Herbed / Spiced Beer</th>\n",
              "      <th>beer/style_Irish Dry Stout</th>\n",
              "      <th>beer/style_Irish Red Ale</th>\n",
              "      <th>beer/style_Keller Bier / Zwickel Bier</th>\n",
              "      <th>beer/style_Kristalweizen</th>\n",
              "      <th>beer/style_KÃ¶lsch</th>\n",
              "      <th>beer/style_Lambic - Fruit</th>\n",
              "      <th>beer/style_Lambic - Unblended</th>\n",
              "      <th>beer/style_Light Lager</th>\n",
              "      <th>beer/style_Low Alcohol Beer</th>\n",
              "      <th>beer/style_Maibock / Helles Bock</th>\n",
              "      <th>beer/style_Milk / Sweet Stout</th>\n",
              "      <th>beer/style_Munich Dunkel Lager</th>\n",
              "      <th>beer/style_Munich Helles Lager</th>\n",
              "      <th>beer/style_MÃ¤rzen / Oktoberfest</th>\n",
              "      <th>beer/style_Oatmeal Stout</th>\n",
              "      <th>beer/style_Old Ale</th>\n",
              "      <th>beer/style_Pumpkin Ale</th>\n",
              "      <th>beer/style_Quadrupel (Quad)</th>\n",
              "      <th>beer/style_Rauchbier</th>\n",
              "      <th>beer/style_Russian Imperial Stout</th>\n",
              "      <th>beer/style_Rye Beer</th>\n",
              "      <th>beer/style_Saison / Farmhouse Ale</th>\n",
              "      <th>beer/style_Schwarzbier</th>\n",
              "      <th>beer/style_Scotch Ale / Wee Heavy</th>\n",
              "      <th>beer/style_Scottish Ale</th>\n",
              "      <th>beer/style_Scottish Gruit / Ancient Herbed Ale</th>\n",
              "      <th>beer/style_Smoked Beer</th>\n",
              "      <th>beer/style_Tripel</th>\n",
              "      <th>beer/style_Vienna Lager</th>\n",
              "      <th>beer/style_Weizenbock</th>\n",
              "      <th>beer/style_Wheatwine</th>\n",
              "      <th>beer/style_Winter Warmer</th>\n",
              "      <th>beer/style_Witbier</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.70</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.40</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.40</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37495</th>\n",
              "      <td>5.50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37496</th>\n",
              "      <td>8.50</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37497</th>\n",
              "      <td>4.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37498</th>\n",
              "      <td>11.20</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37499</th>\n",
              "      <td>8.50</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>37500 rows × 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       beer/ABV  ...  beer/style_Witbier\n",
              "0          5.00  ...                 0.0\n",
              "1         11.00  ...                 0.0\n",
              "2          4.70  ...                 0.0\n",
              "3          4.40  ...                 0.0\n",
              "4          4.40  ...                 0.0\n",
              "...         ...  ...                 ...\n",
              "37495      5.50  ...                 0.0\n",
              "37496      8.50  ...                 0.0\n",
              "37497      4.75  ...                 0.0\n",
              "37498     11.20  ...                 0.0\n",
              "37499      8.50  ...                 0.0\n",
              "\n",
              "[37500 rows x 100 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHol938cW8zd",
        "colab_type": "text"
      },
      "source": [
        "### Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-TDt0Y_XEfc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNw3FeyuT4LL",
        "colab_type": "text"
      },
      "source": [
        "Futher spliting Test set into Test set and Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibZ89aIUTtS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcLkesmJahlk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f358b89-0dba-4e72-e6b8-c5d37c666bd2"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(26250, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RE_FcHyfV3TQ",
        "colab_type": "text"
      },
      "source": [
        "### Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ViCrE00rV8Sk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "X_val = sc.transform(X_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWLSLDP5yllg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1b384e86-1c57-4542-cfd9-4beb14579852"
      },
      "source": [
        "X_val.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3375, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zfEzkRVXIwF",
        "colab_type": "text"
      },
      "source": [
        "## Part 2 - Building the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3xx9fvmVkqB",
        "colab_type": "text"
      },
      "source": [
        "I am starting with ANN if it does not worked I will switch to other algorithm an see which works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBwWAB24WzIL",
        "colab_type": "text"
      },
      "source": [
        "Defining Callback Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBRyj5kcWxuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "es = EarlyStopping(monitor='loss', patience=3)\n",
        "filepath=\"/content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\"\n",
        "md = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YT3YEJLGXanc",
        "colab_type": "text"
      },
      "source": [
        "Defining Important Variable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gylJBRodXheP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Important Variables\n",
        "epochs = 100\n",
        "num_classes = 10\n",
        "batch_size = 1024\n",
        "input_shape = (100,)\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvdeScabXtlB",
        "colab_type": "text"
      },
      "source": [
        "### Initializing the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dtrScHxXQox",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "13faa844-a35d-4044-b3df-608dbcc3736e"
      },
      "source": [
        "ann = Sequential()\n",
        "# 1st Dense Layer\n",
        "ann.add(Dense(units=100, input_shape=input_shape, activation='relu'))\n",
        "ann.add(Dropout(0.25))\n",
        "\n",
        "# 2nd Dense Layer\n",
        "ann.add(Dense(units=50, activation='relu'))\n",
        "ann.add(Dropout(0.25))\n",
        "\n",
        "# 3rd Dense Layer\n",
        "ann.add(Dense(units=25, activation='relu'))\n",
        "ann.add(Dropout(0.25))\n",
        "\n",
        "# output layer\n",
        "ann.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# Compiling the ANN\n",
        "ann.compile(optimizer = adam, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "# Summery of ANN\n",
        "ann.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 16,685\n",
            "Trainable params: 16,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c40Jsg-ZiNe",
        "colab_type": "text"
      },
      "source": [
        "## Part 3 - Training the ANN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QR_G5u7ZLSM",
        "colab_type": "text"
      },
      "source": [
        "### Training the ANN on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHZ-LKv_ZRb3",
        "colab_type": "code",
        "outputId": "1f883c97-958a-4381-b881-fabdc87e22fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "History = ann.fit(X_train,\n",
        "                    y_train, \n",
        "                    batch_size=batch_size,\n",
        "                    #steps_per_epoch=2048,\n",
        "                    epochs = epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data = (X_test, y_test),\n",
        "                    callbacks = [es,md],\n",
        "                    shuffle= True\n",
        "                    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.57470, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 1s - loss: 2.5747 - accuracy: 0.1134 - val_loss: 2.2851 - val_accuracy: 0.1285\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 00002: loss improved from 2.57470 to 2.39947, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.3995 - accuracy: 0.1456 - val_loss: 2.1732 - val_accuracy: 0.2248\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 00003: loss improved from 2.39947 to 2.28371, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.2837 - accuracy: 0.1851 - val_loss: 2.0980 - val_accuracy: 0.2804\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 00004: loss improved from 2.28371 to 2.20547, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.2055 - accuracy: 0.2117 - val_loss: 2.0385 - val_accuracy: 0.3186\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 00005: loss improved from 2.20547 to 2.14974, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.1497 - accuracy: 0.2340 - val_loss: 1.9849 - val_accuracy: 0.3469\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 00006: loss improved from 2.14974 to 2.08903, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.0890 - accuracy: 0.2595 - val_loss: 1.9357 - val_accuracy: 0.3619\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 00007: loss improved from 2.08903 to 2.05311, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.0531 - accuracy: 0.2758 - val_loss: 1.8891 - val_accuracy: 0.3763\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 00008: loss improved from 2.05311 to 2.00497, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 2.0050 - accuracy: 0.2898 - val_loss: 1.8472 - val_accuracy: 0.3870\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 00009: loss improved from 2.00497 to 1.96690, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.9669 - accuracy: 0.2993 - val_loss: 1.8090 - val_accuracy: 0.3887\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 00010: loss improved from 1.96690 to 1.92753, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.9275 - accuracy: 0.3143 - val_loss: 1.7751 - val_accuracy: 0.3881\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 00011: loss improved from 1.92753 to 1.89654, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.8965 - accuracy: 0.3182 - val_loss: 1.7447 - val_accuracy: 0.3883\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 00012: loss improved from 1.89654 to 1.87036, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.8704 - accuracy: 0.3186 - val_loss: 1.7183 - val_accuracy: 0.3878\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 00013: loss improved from 1.87036 to 1.85832, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.8583 - accuracy: 0.3277 - val_loss: 1.6952 - val_accuracy: 0.3888\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 00014: loss improved from 1.85832 to 1.82762, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.8276 - accuracy: 0.3291 - val_loss: 1.6746 - val_accuracy: 0.3897\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 00015: loss improved from 1.82762 to 1.80647, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.8065 - accuracy: 0.3278 - val_loss: 1.6555 - val_accuracy: 0.3925\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 00016: loss improved from 1.80647 to 1.79849, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7985 - accuracy: 0.3333 - val_loss: 1.6386 - val_accuracy: 0.3931\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 00017: loss improved from 1.79849 to 1.77704, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7770 - accuracy: 0.3346 - val_loss: 1.6224 - val_accuracy: 0.3953\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 00018: loss improved from 1.77704 to 1.76406, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7641 - accuracy: 0.3371 - val_loss: 1.6074 - val_accuracy: 0.3980\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 00019: loss improved from 1.76406 to 1.74955, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7496 - accuracy: 0.3368 - val_loss: 1.5940 - val_accuracy: 0.3985\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 00020: loss improved from 1.74955 to 1.73328, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7333 - accuracy: 0.3445 - val_loss: 1.5807 - val_accuracy: 0.3992\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 00021: loss improved from 1.73328 to 1.72075, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7207 - accuracy: 0.3472 - val_loss: 1.5676 - val_accuracy: 0.3986\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 00022: loss improved from 1.72075 to 1.71283, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.7128 - accuracy: 0.3443 - val_loss: 1.5561 - val_accuracy: 0.4005\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 00023: loss improved from 1.71283 to 1.69746, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6975 - accuracy: 0.3519 - val_loss: 1.5449 - val_accuracy: 0.4011\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 00024: loss improved from 1.69746 to 1.67948, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6795 - accuracy: 0.3520 - val_loss: 1.5339 - val_accuracy: 0.4015\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 00025: loss improved from 1.67948 to 1.67825, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6783 - accuracy: 0.3501 - val_loss: 1.5235 - val_accuracy: 0.4022\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 00026: loss improved from 1.67825 to 1.66586, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6659 - accuracy: 0.3565 - val_loss: 1.5137 - val_accuracy: 0.4024\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 00027: loss improved from 1.66586 to 1.64961, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6496 - accuracy: 0.3576 - val_loss: 1.5039 - val_accuracy: 0.4028\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 00028: loss improved from 1.64961 to 1.64757, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6476 - accuracy: 0.3586 - val_loss: 1.4942 - val_accuracy: 0.4050\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 00029: loss improved from 1.64757 to 1.63803, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6380 - accuracy: 0.3585 - val_loss: 1.4855 - val_accuracy: 0.4063\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 00030: loss improved from 1.63803 to 1.62794, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6279 - accuracy: 0.3595 - val_loss: 1.4761 - val_accuracy: 0.4058\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 00031: loss improved from 1.62794 to 1.62139, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6214 - accuracy: 0.3670 - val_loss: 1.4679 - val_accuracy: 0.4070\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 00032: loss improved from 1.62139 to 1.60773, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.6077 - accuracy: 0.3672 - val_loss: 1.4591 - val_accuracy: 0.4102\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 00033: loss improved from 1.60773 to 1.59680, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5968 - accuracy: 0.3699 - val_loss: 1.4503 - val_accuracy: 0.4104\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 00034: loss improved from 1.59680 to 1.59215, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5922 - accuracy: 0.3699 - val_loss: 1.4416 - val_accuracy: 0.4109\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 00035: loss improved from 1.59215 to 1.58596, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5860 - accuracy: 0.3678 - val_loss: 1.4344 - val_accuracy: 0.4141\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 00036: loss improved from 1.58596 to 1.57605, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5761 - accuracy: 0.3743 - val_loss: 1.4261 - val_accuracy: 0.4161\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 00037: loss improved from 1.57605 to 1.56253, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5625 - accuracy: 0.3760 - val_loss: 1.4173 - val_accuracy: 0.4177\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 00038: loss improved from 1.56253 to 1.56053, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5605 - accuracy: 0.3790 - val_loss: 1.4098 - val_accuracy: 0.4211\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 00039: loss improved from 1.56053 to 1.55066, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5507 - accuracy: 0.3772 - val_loss: 1.4015 - val_accuracy: 0.4223\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 00040: loss improved from 1.55066 to 1.54372, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5437 - accuracy: 0.3852 - val_loss: 1.3939 - val_accuracy: 0.4270\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 00041: loss improved from 1.54372 to 1.53273, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5327 - accuracy: 0.3865 - val_loss: 1.3860 - val_accuracy: 0.4309\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 00042: loss improved from 1.53273 to 1.53081, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5308 - accuracy: 0.3839 - val_loss: 1.3783 - val_accuracy: 0.4314\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 00043: loss improved from 1.53081 to 1.51945, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5194 - accuracy: 0.3913 - val_loss: 1.3707 - val_accuracy: 0.4329\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 00044: loss improved from 1.51945 to 1.50659, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5066 - accuracy: 0.3916 - val_loss: 1.3628 - val_accuracy: 0.4383\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 00045: loss improved from 1.50659 to 1.50130, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.5013 - accuracy: 0.3939 - val_loss: 1.3556 - val_accuracy: 0.4424\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 00046: loss improved from 1.50130 to 1.49626, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4963 - accuracy: 0.3976 - val_loss: 1.3493 - val_accuracy: 0.4477\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 00047: loss improved from 1.49626 to 1.48810, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4881 - accuracy: 0.3960 - val_loss: 1.3429 - val_accuracy: 0.4513\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 00048: loss improved from 1.48810 to 1.48194, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4819 - accuracy: 0.4002 - val_loss: 1.3367 - val_accuracy: 0.4526\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 00049: loss improved from 1.48194 to 1.46997, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4700 - accuracy: 0.4033 - val_loss: 1.3302 - val_accuracy: 0.4559\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 00050: loss did not improve from 1.46997\n",
            "26/26 - 0s - loss: 1.4705 - accuracy: 0.4036 - val_loss: 1.3247 - val_accuracy: 0.4573\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 00051: loss improved from 1.46997 to 1.46168, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4617 - accuracy: 0.4050 - val_loss: 1.3190 - val_accuracy: 0.4594\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 00052: loss improved from 1.46168 to 1.45522, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4552 - accuracy: 0.4089 - val_loss: 1.3134 - val_accuracy: 0.4596\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 00053: loss improved from 1.45522 to 1.45406, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4541 - accuracy: 0.4143 - val_loss: 1.3080 - val_accuracy: 0.4599\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 00054: loss improved from 1.45406 to 1.45041, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4504 - accuracy: 0.4112 - val_loss: 1.3037 - val_accuracy: 0.4622\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 00055: loss improved from 1.45041 to 1.43778, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4378 - accuracy: 0.4148 - val_loss: 1.2988 - val_accuracy: 0.4648\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 00056: loss improved from 1.43778 to 1.43375, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4337 - accuracy: 0.4153 - val_loss: 1.2946 - val_accuracy: 0.4679\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 00057: loss improved from 1.43375 to 1.42982, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4298 - accuracy: 0.4175 - val_loss: 1.2898 - val_accuracy: 0.4709\n",
            "Epoch 58/100\n",
            "\n",
            "Epoch 00058: loss improved from 1.42982 to 1.42384, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4238 - accuracy: 0.4213 - val_loss: 1.2857 - val_accuracy: 0.4723\n",
            "Epoch 59/100\n",
            "\n",
            "Epoch 00059: loss improved from 1.42384 to 1.41893, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4189 - accuracy: 0.4219 - val_loss: 1.2816 - val_accuracy: 0.4721\n",
            "Epoch 60/100\n",
            "\n",
            "Epoch 00060: loss improved from 1.41893 to 1.41679, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4168 - accuracy: 0.4224 - val_loss: 1.2778 - val_accuracy: 0.4744\n",
            "Epoch 61/100\n",
            "\n",
            "Epoch 00061: loss improved from 1.41679 to 1.41326, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4133 - accuracy: 0.4234 - val_loss: 1.2743 - val_accuracy: 0.4766\n",
            "Epoch 62/100\n",
            "\n",
            "Epoch 00062: loss improved from 1.41326 to 1.40406, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.4041 - accuracy: 0.4308 - val_loss: 1.2706 - val_accuracy: 0.4766\n",
            "Epoch 63/100\n",
            "\n",
            "Epoch 00063: loss did not improve from 1.40406\n",
            "26/26 - 0s - loss: 1.4044 - accuracy: 0.4288 - val_loss: 1.2667 - val_accuracy: 0.4773\n",
            "Epoch 64/100\n",
            "\n",
            "Epoch 00064: loss improved from 1.40406 to 1.39344, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3934 - accuracy: 0.4307 - val_loss: 1.2632 - val_accuracy: 0.4764\n",
            "Epoch 65/100\n",
            "\n",
            "Epoch 00065: loss did not improve from 1.39344\n",
            "26/26 - 0s - loss: 1.3936 - accuracy: 0.4310 - val_loss: 1.2605 - val_accuracy: 0.4797\n",
            "Epoch 66/100\n",
            "\n",
            "Epoch 00066: loss improved from 1.39344 to 1.39018, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3902 - accuracy: 0.4323 - val_loss: 1.2575 - val_accuracy: 0.4808\n",
            "Epoch 67/100\n",
            "\n",
            "Epoch 00067: loss improved from 1.39018 to 1.38912, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3891 - accuracy: 0.4322 - val_loss: 1.2544 - val_accuracy: 0.4805\n",
            "Epoch 68/100\n",
            "\n",
            "Epoch 00068: loss improved from 1.38912 to 1.37614, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3761 - accuracy: 0.4384 - val_loss: 1.2523 - val_accuracy: 0.4809\n",
            "Epoch 69/100\n",
            "\n",
            "Epoch 00069: loss improved from 1.37614 to 1.37512, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3751 - accuracy: 0.4385 - val_loss: 1.2493 - val_accuracy: 0.4829\n",
            "Epoch 70/100\n",
            "\n",
            "Epoch 00070: loss improved from 1.37512 to 1.37229, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3723 - accuracy: 0.4408 - val_loss: 1.2475 - val_accuracy: 0.4825\n",
            "Epoch 71/100\n",
            "\n",
            "Epoch 00071: loss did not improve from 1.37229\n",
            "26/26 - 0s - loss: 1.3755 - accuracy: 0.4382 - val_loss: 1.2452 - val_accuracy: 0.4838\n",
            "Epoch 72/100\n",
            "\n",
            "Epoch 00072: loss improved from 1.37229 to 1.36262, saving model to /content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\n",
            "26/26 - 0s - loss: 1.3626 - accuracy: 0.4450 - val_loss: 1.2424 - val_accuracy: 0.4853\n",
            "Epoch 73/100\n",
            "\n",
            "Epoch 00073: loss did not improve from 1.36262\n",
            "26/26 - 0s - loss: 1.3648 - accuracy: 0.4427 - val_loss: 1.2402 - val_accuracy: 0.4858\n",
            "Epoch 74/100\n",
            "\n",
            "Epoch 00074: loss did not improve from 1.36262\n",
            "26/26 - 0s - loss: 1.3639 - accuracy: 0.4449 - val_loss: 1.2382 - val_accuracy: 0.4852\n",
            "Epoch 75/100\n",
            "\n",
            "Epoch 00075: loss did not improve from 1.36262\n",
            "26/26 - 0s - loss: 1.3639 - accuracy: 0.4426 - val_loss: 1.2366 - val_accuracy: 0.4861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJj5k2MxZga3",
        "colab_type": "text"
      },
      "source": [
        "## Part 4 - Making the predictions and evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yx47jPZt11",
        "colab_type": "text"
      },
      "source": [
        "### Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIyEeQdRZwgs",
        "colab_type": "code",
        "outputId": "71b6ae7b-0cf9-4639-9318-601d35c00d7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "ann2 = load_model(\"/content/drive/My Drive/Colab Notebooks/Model/bestmodel.h5\")\n",
        "# Summery of ANN2\n",
        "ann2.summary()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 25)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                260       \n",
            "=================================================================\n",
            "Total params: 16,685\n",
            "Trainable params: 16,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0oyfLWoaEGw",
        "colab_type": "text"
      },
      "source": [
        "### Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEoMqNV6ADbu",
        "colab_type": "text"
      },
      "source": [
        "As it seems ANN is falled to provide Nessary solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci6K_r6LaF6P",
        "colab_type": "code",
        "outputId": "f50c1c7b-8f89-48ac-cf1b-e229d9503d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "y_pred = ann2.predict_classes(X_val)\n",
        "y_pred = y_pred*0.5\n",
        "print(y_pred)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-58c9a1a3bea4>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
            "Instructions for updating:\n",
            "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "[3.5 3.  3.  ... 2.5 4.  3.5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hofwX5mWFIHY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "32453ccf-232e-4914-8d11-8454f537ec66"
      },
      "source": [
        "y_val.columns"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['review/overall_0.0', 'review/overall_1.0', 'review/overall_1.5',\n",
              "       'review/overall_2.0', 'review/overall_2.5', 'review/overall_3.0',\n",
              "       'review/overall_3.5', 'review/overall_4.0', 'review/overall_4.5',\n",
              "       'review/overall_5.0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvdAlJ42AB40",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val.set_index('review/overall_0.0', inplace=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGGChf18GHFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y_vall =y_val[y_val==1].stack().reset_index().drop(0,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIZkJKewHMsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "70d44db7-6fe7-464a-b6ac-2b1ef0548bb3"
      },
      "source": [
        "y_val.columns"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['review/overall_1.0', 'review/overall_1.5', 'review/overall_2.0',\n",
              "       'review/overall_2.5', 'review/overall_3.0', 'review/overall_3.5',\n",
              "       'review/overall_4.0', 'review/overall_4.5', 'review/overall_5.0'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoT6HbiqGjl9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val = Y_vall.drop(['review/overall_0.0'], axis=1, inplace=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK57iDyPHmvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def funct(x):\n",
        " \n",
        "  if x == 'review/overall_0.0':\n",
        "    return 0\n",
        "  elif x == 'review/overall_1.0':\n",
        "    return 1\n",
        "  elif x== 'review/overall_1.5':\n",
        "    return 1.5\n",
        "  elif x== 'review/overall_2.0':\n",
        "    return 2\n",
        "  elif x== 'review/overall_2.5':\n",
        "    return 2.5\n",
        "  elif x== 'review/overall_3.0':\n",
        "    return 3\n",
        "  elif x== 'review/overall_3.5':\n",
        "    return 3.5\n",
        "  elif x== 'review/overall_4.0':\n",
        "    return 4\n",
        "  elif x== 'review/overall_4.5':\n",
        "    return 4.5\n",
        "  else:\n",
        "    return 5\n",
        "\n",
        "\n",
        "y_val['review'] = y_val.apply(lambda x:funct(x['level_1']),axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhGQ18SrQPaS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "95e649bd-6292-4bc3-fda3-78dc6b7ffe8e"
      },
      "source": [
        "y_val['review']"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       4.5\n",
              "1       3.0\n",
              "2       3.5\n",
              "3       5.0\n",
              "4       4.0\n",
              "       ... \n",
              "3370    4.0\n",
              "3371    3.5\n",
              "3372    3.5\n",
              "3373    5.0\n",
              "3374    4.0\n",
              "Name: review, Length: 3375, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbyrP_BZHhmO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN-kGUnRHl3F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62f1130c-d7f6-4e2a-e3e3-c295fd4b7312"
      },
      "source": [
        "# function to check predicted accuracy\n",
        "def accuracy(df,k):\n",
        "  k = 0\n",
        "  for i in range(len(df)):\n",
        "    if df[i] == y_pred[i]:\n",
        "      k = k+1\n",
        "  \n",
        "  acc = (k*100)/len(y_val)\n",
        "  return acc\n",
        "\n",
        "print(accuracy(y_val['review'], y_pred))\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20.94814814814815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSdM4AsiSvgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Poor accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}